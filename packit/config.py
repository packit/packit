import json
import logging
from enum import IntEnum
from functools import lru_cache
from os import getenv
from pathlib import Path
from typing import Optional, List, NamedTuple

import anymarkup
import click
import jsonschema
from jsonschema import Draft4Validator

from ogr.abstract import GitProject
from packit.constants import CONFIG_FILE_NAMES
from packit.exceptions import PackitConfigException
from packit.utils import exclude_from_dict

logger = logging.getLogger(__name__)


class Config:
    def __init__(self):
        self.debug = False
        self.fas_user = None
        self.keytab_path = None
        self._package_config = None
        self._github_token = None
        self._pagure_user_token = None
        self._pagure_package_token = None
        self._pagure_fork_token = None

    @property
    def github_token(self) -> str:
        if self._github_token is None:
            self._github_token = getenv("GITHUB_TOKEN", "")
        return self._github_token

    @property
    def pagure_user_token(self) -> str:
        if self._pagure_user_token is None:
            self._pagure_user_token = getenv("PAGURE_USER_TOKEN", "")
        return self._pagure_user_token

    @property
    def pagure_package_token(self) -> str:
        """ this token is used to comment on pull requests """
        if self._pagure_package_token is None:
            self._pagure_package_token = getenv("PAGURE_PACKAGE_TOKEN", "")
        return self._pagure_package_token

    @property
    def pagure_fork_token(self) -> str:
        """ this is needed to create pull requests """
        if self._pagure_fork_token is None:
            self._pagure_fork_token = getenv("PAGURE_FORK_TOKEN", "")
        return self._pagure_fork_token


pass_config = click.make_pass_decorator(Config)


def get_default_map_from_file() -> Optional[dict]:
    config_path = Path(".packit")
    if config_path.is_file():
        return json.loads(config_path.read_text())
    return None


@lru_cache()
def get_context_settings() -> dict:
    return dict(
        help_option_names=["-h", "--help"],
        auto_envvar_prefix="PACKIT",
        default_map=get_default_map_from_file(),
    )


class TriggerType(IntEnum):
    release = 1
    pull_request = 2
    git_tag = 3


class JobConfig(NamedTuple):
    trigger: TriggerType
    release_to: List[str]
    metadata: dict

    @classmethod
    def get_from_dict(cls, raw_dict: dict, validate=True) -> "JobConfig":
        if validate and not JobConfig.is_dict_valid(raw_dict):
            raise Exception(f"Job config not valid.")

        trigger_raw, release_to, metadata = exclude_from_dict(
            raw_dict, "trigger", "release_to"
        )
        return JobConfig(
            trigger=TriggerType[trigger_raw], release_to=release_to, metadata=metadata
        )

    @classmethod
    def is_dict_valid(cls, raw_dict: dict) -> bool:
        return Draft4Validator(JOB_CONFIG_SCHEMA).is_valid(raw_dict)


class PackageConfig:
    """
    Config class for upstream/downstream packages;
    this is the config people put in their repos
    """

    def __init__(
        self,
        specfile_path: Optional[str] = None,
        synced_files: Optional[List[str]] = None,
        jobs: Optional[List[JobConfig]] = None,
        dist_git_namespace: str = None,
        upstream_project_url: str = None,  # can be URL or path
        upstream_project_name: str = None,
        downstream_project_url: str = None,
        downstream_package_name: str = None,
        dist_git_base_url: str = None,
        create_tarball_command: List[str] = None,
        current_version_command: List[str] = None,
    ):
        self.specfile_path: Optional[str] = specfile_path
        self.synced_files: List[str] = synced_files or []
        self.jobs: List[JobConfig] = jobs or []
        self.dist_git_namespace: str = dist_git_namespace or "rpms"
        self.upstream_project_url: Optional[str] = upstream_project_url
        self.upstream_project_name: Optional[str] = upstream_project_name
        # this is generated by us
        self.downstream_project_url: Optional[str] = downstream_project_url
        self.downstream_package_name: Optional[str] = downstream_package_name
        self.dist_git_base_url: str = dist_git_base_url or "https://src.fedoraproject.org/"

        # command to generate a tarball from the upstream repo
        # uncommitted changes will not be present in the archive
        self.create_tarball_command: List[str] = create_tarball_command
        # command to get current version of the project
        if current_version_command:
            self.current_version_command: List[str] = current_version_command
        else:
            self.current_version_command: List[str] = [
                "git",
                "describe",
                "--tags",
                "--match",
                "*.*",
            ]

    def __eq__(self, other: object):
        if not isinstance(other, self.__class__):
            return NotImplemented
        logger.debug(f"our configuration:\n{self.__dict__}")
        logger.debug(f"the other configuration:\n{other.__dict__}")
        return (
            self.specfile_path == other.specfile_path
            and self.synced_files == other.synced_files
            and self.jobs == other.jobs
            and self.dist_git_namespace == other.dist_git_namespace
            and self.upstream_project_url == other.upstream_project_url
            and self.upstream_project_name == other.upstream_project_name
            and self.downstream_project_url == other.downstream_project_url
            and self.downstream_package_name == other.downstream_package_name
            and self.dist_git_base_url == other.dist_git_base_url
            and self.current_version_command == other.current_version_command
            and self.create_tarball_command == other.create_tarball_command
        )

    @property
    def dist_git_package_url(self):
        return (
            f"{self.dist_git_base_url}{self.dist_git_namespace}/"
            f"{self.downstream_package_name}.git"
        )

    @classmethod
    def get_from_dict(cls, raw_dict: dict, validate=True) -> "PackageConfig":
        if validate:
            PackageConfig.validate_dict(raw_dict)

        specfile_path = raw_dict.get("specfile_path", None)
        synced_files = raw_dict.get("synced_files", None)
        raw_jobs = raw_dict.get("jobs", [])
        create_tarball_command = raw_dict.get("create_tarball_command", None)
        current_version_command = raw_dict.get("current_version_command", None)

        upstream_project_name = cls.get_deprecated_key(
            raw_dict, "upstream_project_name", "upstream_name"
        )
        upstream_project_url = raw_dict.get("upstream_project_url", None)

        if raw_dict.get("dist_git_url", None):
            logger.warning(
                "dist_git_url is no longer being processed, "
                "it is generated from dist_git_base_url and downstream_package_name"
            )
        downstream_package_name = cls.get_deprecated_key(
            raw_dict, "downstream_package_name", "package_name"
        )

        dist_git_base_url = raw_dict.get("dist_git_base_url", None)
        dist_git_namespace = raw_dict.get("dist_git_namespace", None)

        pc = PackageConfig(
            specfile_path=specfile_path,
            synced_files=synced_files,
            jobs=[
                JobConfig.get_from_dict(raw_job, validate=False) for raw_job in raw_jobs
            ],
            upstream_project_name=upstream_project_name,
            downstream_package_name=downstream_package_name,
            upstream_project_url=upstream_project_url,
            dist_git_base_url=dist_git_base_url,
            dist_git_namespace=dist_git_namespace,
            create_tarball_command=create_tarball_command,
            current_version_command=current_version_command,
        )

        return pc

    @staticmethod
    def get_deprecated_key(raw_dict: dict, new_key_name: str, old_key_name: str):
        old = raw_dict.get(old_key_name, None)
        if old:
            logger.warning(
                f"{old_key_name!r} configuration key was renamed to {new_key_name!r},"
                f" please update your configuration file"
            )
        r = raw_dict.get(new_key_name, None)
        if not r:
            # prio: new > old
            r = old
        return r

    @classmethod
    def validate_dict(cls, raw_dict: dict) -> None:
        jsonschema.validate(raw_dict, PACKAGE_CONFIG_SCHEMA)


def get_local_package_config(
    *directory, try_local_dir_first=False, try_local_dir_last=False
) -> PackageConfig:
    """
    :return: local PackageConfig if present
    """
    directories = [Path(config_dir) for config_dir in directory]

    if try_local_dir_first:
        directories.insert(0, Path.cwd())

    if try_local_dir_last:
        directories.append(Path.cwd())

    for config_dir in directories:
        for config_file_name in CONFIG_FILE_NAMES:
            config_file_name_full = config_dir / config_file_name
            if config_file_name_full.is_file():
                logger.debug(f"Local package config found: {config_file_name_full}")
                try:
                    loaded_config = anymarkup.parse_file(config_file_name_full)
                except Exception as ex:
                    logger.error(
                        f"Cannot load package config '{config_file_name_full}'."
                    )
                    raise Exception(f"Cannot load package config: {ex}.")

                return parse_loaded_config(loaded_config=loaded_config)

            logger.debug(f"The local config file '{config_file_name_full}' not found.")
    raise PackitConfigException("No packit config found.")


def get_packit_config_from_repo(
    sourcegit_project: GitProject, ref: str
) -> Optional[PackageConfig]:
    for config_file_name in CONFIG_FILE_NAMES:
        try:
            config_file = sourcegit_project.get_file_content(
                path=config_file_name, ref=ref
            )
            logger.debug(
                f"Found a config file '{config_file_name}' "
                f"on ref '{ref}' "
                f"of the {sourcegit_project.full_repo_name} repository."
            )
        except FileNotFoundError:
            logger.debug(
                f"The config file '{config_file_name}' "
                f"not found on ref '{ref}' "
                f"of the {sourcegit_project.full_repo_name} repository."
            )
            continue

        try:
            loaded_config = anymarkup.parse(config_file)
        except Exception as ex:
            logger.error(f"Cannot load package config '{config_file_name}'.")
            raise Exception(f"Cannot load package config: {ex}.")

        return parse_loaded_config(loaded_config=loaded_config)

    return None


def parse_loaded_config(loaded_config: dict) -> PackageConfig:
    """Tries to parse the config to PackageConfig."""
    logger.debug(f"Package config:\n{json.dumps(loaded_config, indent=4)}")

    try:
        package_config = PackageConfig.get_from_dict(
            raw_dict=loaded_config, validate=True
        )
        return package_config
    except Exception as ex:
        logger.error(f"Cannot parse package config. {ex}.")
        raise Exception(f"Cannot parse package config: {ex}.")


JOB_CONFIG_SCHEMA = {
    "type": "object",
    "properties": {
        "trigger": {"enum": ["release", "pull_request", "git_tag"]},
        "release_to": {"type": "array", "items": {"type": "string"}},
    },
    "required": ["trigger", "release_to"],
}

PACKAGE_CONFIG_SCHEMA = {
    "type": "object",
    "properties": {
        "specfile_path": {"type": "string"},
        "downstream_package_name": {"type": "string"},
        "upstream_project_name": {"type": "string"},
        "create_tarball_command": {"type": "array", "items": {"type": "string"}},
        "current_version_command": {"type": "array", "items": {"type": "string"}},
        "synced_files": {"type": "array", "items": {"type": "string"}},
        "jobs": {"type": "array", "items": JOB_CONFIG_SCHEMA},
    },
    "required": ["specfile_path", "synced_files"],
}
